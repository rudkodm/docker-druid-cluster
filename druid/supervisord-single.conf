[supervisord]
nodaemon=true
loglevel=info

[unix_http_server]
file=/tmp/supervisor.sock

[supervisorctl]
serverurl=unix:///tmp/supervisor.sock

[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[program:druid-coordinator]
user=druid
command=java
  -cp %(ENV_DRUID_HOME)s/lib/*
  -server
  -Xmx1g
  -Duser.timezone=UTC
  -Dfile.encoding=UTF-8
  -Ddruid.host=%(ENV_HOSTIP)s
  -Ddruid.extensions.directory=%(ENV_DRUID_HOME)s/extensions
  -Ddruid.extensions.hadoopDependenciesDir=%(ENV_DRUID_HOME)s/hadoop-dependencies
  -Ddruid.extensions.loadList=[\"sqlserver-metadata-storage\",\"druid-azure-extensions\"]
  -Ddruid.zk.service.host=%(ENV_ZOOKEEPER_HOSTS)s
  -Ddruid.metadata.storage.type=%(ENV_METADATA_DB_TYPE)s
  -Ddruid.metadata.storage.connector.connectURI=%(ENV_METADATA_DB_URL)s
  -Ddruid.metadata.storage.connector.user=%(ENV_METADATA_DB_USER)s
  -Ddruid.metadata.storage.connector.password=%(ENV_METADATA_DB_PASSWORD)s
  -Ddruid.storage.type=azure
  -Ddruid.azure.account=%(ENV_AZURE_ACCOUNT)s
  -Ddruid.azure.key=%(ENV_AZURE_KEY)s
  -Ddruid.azure.container=%(ENV_AZURE_CONTAINER)s
  -Ddruid.coordinator.asOverlord.enabled=true
  -Ddruid.coordinator.asOverlord.overlordService=druid/overlord
  -Ddruid.indexer.fork.property.druid.processing.numThreads=1
  -Ddruid.indexer.storage.type=metadata
  -Ddruid.indexer.queue.startDelay=PT0M
  -Ddruid.indexer.runner.javaOpts="-server -Xmx1g -XX:MaxDirectMemorySize=2147483648"
  -Ddruid.processing.buffer.sizeBytes=536870912
  -Ddruid.coordinator.startDelay=PT5S
  -Dlog4j.configurationFile=%(ENV_DRUID_HOME)s/conf/druid/_common/log4j2.xml
  io.druid.cli.Main server coordinator
redirect_stderr=true
priority=100
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0

[program:druid-historical]
user=druid
command=java
  -cp %(ENV_DRUID_HOME)s/lib/*
  -server
  -Xmx1g
  -Duser.timezone=UTC
  -Dfile.encoding=UTF-8
  -Ddruid.host=%(ENV_HOSTIP)s
  -Ddruid.extensions.directory=%(ENV_DRUID_HOME)s/extensions
  -Ddruid.extensions.hadoopDependenciesDir=%(ENV_DRUID_HOME)s/hadoop-dependencies
  -Ddruid.extensions.loadList=[\"sqlserver-metadata-storage\",\"druid-azure-extensions\"]
  -Ddruid.zk.service.host=%(ENV_ZOOKEEPER_HOSTS)s
  -Ddruid.metadata.storage.type=%(ENV_METADATA_DB_TYPE)s
  -Ddruid.metadata.storage.connector.connectURI=%(ENV_METADATA_DB_URL)s
  -Ddruid.metadata.storage.connector.user=%(ENV_METADATA_DB_USER)s
  -Ddruid.metadata.storage.connector.password=%(ENV_METADATA_DB_PASSWORD)s
  -Ddruid.storage.type=azure
  -Ddruid.azure.account=%(ENV_AZURE_ACCOUNT)s
  -Ddruid.azure.key=%(ENV_AZURE_KEY)s
  -Ddruid.azure.container=%(ENV_AZURE_CONTAINER)s
  -Ddruid.computation.buffer.size=67108864
  -Ddruid.segmentCache.locations="[{\"path\":\"/var/tmp/druid/indexCache\",\"maxSize\":5000000000}]"
  -Ddruid.server.maxSize=5000000000
  io.druid.cli.Main server historical
redirect_stderr=true
priority=100
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0

[program:druid-broker]
user=druid
command=java
  -cp %(ENV_DRUID_HOME)s/lib/*
  -server
  -Xmx1g
  -Duser.timezone=UTC
  -Dfile.encoding=UTF-8
  -Ddruid.host=%(ENV_HOSTIP)s
  -Ddruid.extensions.directory=%(ENV_DRUID_HOME)s/extensions
  -Ddruid.extensions.hadoopDependenciesDir=%(ENV_DRUID_HOME)s/hadoop-dependencies
  -Ddruid.extensions.loadList=[\"sqlserver-metadata-storage\",\"druid-azure-extensions\"]
  -Ddruid.zk.service.host=%(ENV_ZOOKEEPER_HOSTS)s
  -Ddruid.computation.buffer.size=67108864
  -Ddruid.broker.cache.sizeInBytes=33554432
  -cp /usr/local/druid/lib/*
  io.druid.cli.Main server broker
redirect_stderr=true
priority=100
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0